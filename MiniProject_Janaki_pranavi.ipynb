{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d37db207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pranavipanduga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae0712",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9878a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('news 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fa36340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d421bc1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c8305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['label'] = news['label'].replace(['FAKE', 'REAL'],[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa82fc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      1  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      1  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      0  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      1  \n",
       "4  It's primary day in New York and front-runners...      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d8eed26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6335.000000</td>\n",
       "      <td>6335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5280.415627</td>\n",
       "      <td>0.499448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3038.503953</td>\n",
       "      <td>0.500039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2674.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5271.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7901.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10557.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        label\n",
       "count   6335.000000  6335.000000\n",
       "mean    5280.415627     0.499448\n",
       "std     3038.503953     0.500039\n",
       "min        2.000000     0.000000\n",
       "25%     2674.500000     0.000000\n",
       "50%     5271.000000     0.000000\n",
       "75%     7901.000000     1.000000\n",
       "max    10557.000000     1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "117c9d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "title         0\n",
       "text          0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a3c4b",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca95927",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e63d4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming (content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ', content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [stem.stem(word) for word in stemmed_content if not word in stopwords.words ('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content\n",
    "news['title'] = news['title'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "066327eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(s):\n",
    "    nopunc = [char for char in s if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    clean_string = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_string\n",
    "news['Clean Text'] = news['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d2303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac21390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/rb93zdc963qdht_9s178ppm80000gn/T/ipykernel_55233/1089151858.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news['text'] = news['text'].str.replace('[^\\w\\s,]', '')\n",
      "/var/folders/gg/rb93zdc963qdht_9s178ppm80000gn/T/ipykernel_55233/1089151858.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news['text'] = news['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "news['text'] = news['text'].str.replace('[^\\w\\s,]', '')\n",
    "news['text'] = news['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "news['text'] = news['text'].str.replace(' ,', ',')\n",
    "news['text'] = news['text'].str.replace(', ', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51fe76c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "news['text'] = news['text'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a60ff64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0                                              title  \\\n",
      "0       8476                                 smell hillari fear   \n",
      "1      10294  watch exact moment paul ryan commit polit suic...   \n",
      "2       3608                      kerri go pari gestur sympathi   \n",
      "3      10142     berni support twitter erupt anger dnc tri warn   \n",
      "4        875                      battl new york primari matter   \n",
      "\n",
      "                                                text label  \\\n",
      "0  [daniel, greenfield, a, shillman, journalism, ...     1   \n",
      "1  [google, pinterest, digg, linkedin, reddit, st...     1   \n",
      "2  [us, secretary, of, state, john, f, kerry, sai...     0   \n",
      "3  [kaydee, king, kaydeeking, november, 9, 2016, ...     1   \n",
      "4  [its, primary, day, in, new, york, and, frontr...     0   \n",
      "\n",
      "                                          Clean Text  \n",
      "0  ['daniel', 'greenfield', 'shillman', 'journali...  \n",
      "1  ['google', 'pinterest', 'digg', 'linkedin', 'r...  \n",
      "2  ['us', 'secretary', 'state', 'john', 'f', 'ker...  \n",
      "3  ['—', 'kaydee', 'king', 'kaydeeking', 'novembe...  \n",
      "4  ['primary', 'day', 'new', 'york', 'frontrunner...  \n"
     ]
    }
   ],
   "source": [
    "print(news.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4811a7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vectorizer1 \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvectorizer1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m vectorizedtfidf \u001b[38;5;241m=\u001b[39m vectorizer1\u001b[38;5;241m.\u001b[39mtransform([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(news[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])])\n\u001b[1;32m      5\u001b[0m vectorizer2 \u001b[38;5;241m=\u001b[39m CountVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2101\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n\u001b[1;32m   2095\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2096\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2097\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2098\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2099\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2100\u001b[0m )\n\u001b[0;32m-> 2101\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1380\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m             )\n\u001b[1;32m   1385\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1387\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1390\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1274\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1273\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(max_features=2000)\n",
    "vectorizer1.fit(news['text'])\n",
    "vectorizedtfidf = vectorizer1.transform([' '.join(news['text'])])\n",
    "\n",
    "vectorizer2 = CountVectorizer(max_features=2000)\n",
    "vectorizer2.fit(news['text'])\n",
    "vectorizedbow = vectorizer2.transform([' '.join(news['text'])])\n",
    "\n",
    "print(\"Shape of the TF-IDF vector: \", vectorizedtfidf.shape)\n",
    "print(\"Shape of the BOW vector: \", vectorizedbow.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ea0f30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>2951</td>\n",
       "      <td>airstrik move syria target isi</td>\n",
       "      <td>[airstrikes, move, to, syria, target, more, th...</td>\n",
       "      <td>0</td>\n",
       "      <td>['airstrikes', 'move', 'syria', 'target', 'isi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>9424</td>\n",
       "      <td>currenc crisi alasdair macleod vex question do...</td>\n",
       "      <td>[tweet, home, gold, gold, news, currency, cris...</td>\n",
       "      <td>1</td>\n",
       "      <td>['tweet', 'home', '»', 'gold', '»', 'gold', 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>3974</td>\n",
       "      <td>enter u refuge would hard terrorist</td>\n",
       "      <td>[washington, cnn, even, before, the, debris, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>['washington', 'cnn', 'even', 'debris', 'paris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>525</td>\n",
       "      <td>obama budget would fund public work program ta...</td>\n",
       "      <td>[president, obama, unveiled, a, 4, trillion, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>['president', 'obama', 'unveiled', '4', 'trill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>7791</td>\n",
       "      <td>donald trump announc urban revit plan black am...</td>\n",
       "      <td>[drdarrell, scott, pastordscott, october, 27, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['—', 'drdarrell', 'scott', 'pastordscott', 'o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                              title  \\\n",
       "1497       2951                     airstrik move syria target isi   \n",
       "2284       9424  currenc crisi alasdair macleod vex question do...   \n",
       "897        3974                enter u refuge would hard terrorist   \n",
       "2835        525  obama budget would fund public work program ta...   \n",
       "2524       7791  donald trump announc urban revit plan black am...   \n",
       "\n",
       "                                                   text label  \\\n",
       "1497  [airstrikes, move, to, syria, target, more, th...     0   \n",
       "2284  [tweet, home, gold, gold, news, currency, cris...     1   \n",
       "897   [washington, cnn, even, before, the, debris, f...     0   \n",
       "2835  [president, obama, unveiled, a, 4, trillion, b...     0   \n",
       "2524  [drdarrell, scott, pastordscott, october, 27, ...     1   \n",
       "\n",
       "                                             Clean Text  \n",
       "1497  ['airstrikes', 'move', 'syria', 'target', 'isi...  \n",
       "2284  ['tweet', 'home', '»', 'gold', '»', 'gold', 'n...  \n",
       "897   ['washington', 'cnn', 'even', 'debris', 'paris...  \n",
       "2835  ['president', 'obama', 'unveiled', '4', 'trill...  \n",
       "2524  ['—', 'drdarrell', 'scott', 'pastordscott', 'o...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = news['label'].values\n",
    "label = label.reshape(-1, 1)\n",
    "news.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f75a6",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "014e7a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m      2\u001b[0m vectorizedtfidf_tsne_copy\u001b[38;5;241m=\u001b[39m vectorizedtfidf\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 3\u001b[0m vectorizedtfidf_tsne_copy \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorizedtfidf_tsne_copy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39mvectorizedtfidf_tsne_copy[:,\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mvectorizedtfidf_tsne_copy[:,\u001b[38;5;241m1\u001b[39m], hue\u001b[38;5;241m=\u001b[39mnews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1118\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \n\u001b[1;32m   1099\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m-> 1118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:829\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "vectorizedtfidf_tsne_copy= vectorizedtfidf.copy()\n",
    "vectorizedtfidf_tsne_copy = tsne.fit_transform(vectorizedtfidf_tsne_copy.toarray())\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.scatterplot(x=vectorizedtfidf_tsne_copy[:,0], y=vectorizedtfidf_tsne_copy[:,1], hue=news['label'])\n",
    "plt.title('TSNE on TF-IDF Vector')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5132260",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "vectorizedbow_tsne_copy= vectorizedbow.copy()\n",
    "vectorizedbow_tsne_copy = tsne.fit_transform(vectorizedbow_tsne_copy.toarray())\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=vectorizedbow_tsne_copy[:,0], y=vectorizedbow_tsne_copy[:,1], hue=news['label'])\n",
    "plt.title('TSNE on BoW Vector')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c410c",
   "metadata": {},
   "source": [
    "# TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedtfidf = vectorizedtfidf.toarray()\n",
    "vectorizedbow = vectorizedbow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = news['label'].values\n",
    "print(label)\n",
    "print(vectorizedbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b3d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_reshaped = label.reshape(-1, 1)\n",
    "vectorizedtfidfr = vectorizedtfidf.reshape(-1, 1)\n",
    "\n",
    "news1 = np.concatenate((vectorizedtfidf, label_reshaped), axis=1)\n",
    "news2 = np.concatenate((vectorizedbow, label_reshaped), axis=1)\n",
    "\n",
    "news1_df = pd.DataFrame(news1, columns=[f\"feature_{i}\" for i in range(news1.shape[1]-1)]+[\"label\"])\n",
    "news2_df = pd.DataFrame(news2, columns=[f\"feature_{i}\" for i in range(news2.shape[1]-1)]+[\"label\"])\n",
    "\n",
    "print(news1_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c899d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(news1[:, :-1], news1[:, -1], test_size=0.2, random_state=0)\n",
    "X_val1, X_test1, y_val1, y_test1 = train_test_split(X_test1, y_test1, test_size=0.5, random_state=0)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(news2[:, :-1], news2[:, -1], test_size=0.2, random_state=0)\n",
    "X_val2, X_test2, y_val2, y_test2 = train_test_split(X_test2, y_test2, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beade18",
   "metadata": {},
   "source": [
    "# MODELS: logistic regression, naive bayes, decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10847b",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74186eaa",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = np.logspace(-3, 3, 7)\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for hyperparam in hyperparams:\n",
    "    model = LogisticRegression(C=hyperparam, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    model.fit(X_train1, y_train1)\n",
    "    train_acc = model.score(X_train1, y_train1)\n",
    "    val_acc = model.score(X_val1, y_val1)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "plt.plot(hyperparams, train_accs, label='Training accuracy')\n",
    "plt.plot(hyperparams, val_accs, label='Validation accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Hyperparameter value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_hyperparam = hyperparams[np.argmax(val_accs)]\n",
    "\n",
    "final_model = LogisticRegression(C=best_hyperparam, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "final_model.fit(X_train1, y_train1)\n",
    "test_acc = final_model.score(X_test1, y_test1)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_test1[:, 0], y_test1, color='black', s=20, marker='.')\n",
    "xmin, xmax = plt.xlim()\n",
    "coef = final_model.coef_[0]\n",
    "intercept = final_model.intercept_\n",
    "x_line = np.linspace(xmin, xmax, num=100)\n",
    "y_line = 1 / (1 + np.exp(-(coef[0] * x_line + intercept)))\n",
    "plt.plot(x_line, y_line, color='blue', linewidth=3)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bf276",
   "metadata": {},
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = np.logspace(-3, 3, 7)\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for hyperparam in hyperparams:\n",
    "    model = LogisticRegression(C=hyperparam, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    model.fit(X_train2, y_train2)\n",
    "    train_acc = model.score(X_train2, y_train2)\n",
    "    val_acc = model.score(X_val2, y_val2)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "plt.plot(hyperparams, train_accs, label='Training accuracy')\n",
    "plt.plot(hyperparams, val_accs, label='Validation accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Hyperparameter value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_hyperparam = hyperparams[np.argmax(val_accs)]\n",
    "\n",
    "final_model = LogisticRegression(C=best_hyperparam, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "final_model.fit(X_train2, y_train2)\n",
    "test_acc = final_model.score(X_test2, y_test2)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_test2[:, 0], y_test2, color='black', s=20, marker='.')\n",
    "xmin, xmax = plt.xlim()\n",
    "coef = final_model.coef_[0]\n",
    "intercept = final_model.intercept_\n",
    "x_line = np.linspace(xmin, xmax, num=100)\n",
    "y_line = 1 / (1 + np.exp(-(coef[0] * x_line + intercept)))\n",
    "plt.plot(x_line, y_line, color='blue', linewidth=3)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e5a74",
   "metadata": {},
   "source": [
    "NAIVE BAYES: MULTINOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnblearn(X_train,y_train,X_val,y_val):\n",
    "    mnb=MultinomialNB()\n",
    "    param_grid = {'var_smoothing': np.logspace(0,-9, num=10)}\n",
    "    grid_search = GridSearchCV(gnb, param_grid, cv=3,refit=True,n_jobs=-1,scoring='accuracy',verbose=1)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "    print(\"Accuracy: \",accuracy_score(y_val,grid_search.predict(X_val)))\n",
    "    print(classification_report(y_val,grid_search.predict(X_val)))\n",
    "    train_sizes, train_scores, test_scores = learning_curve(grid_search.best_estimator_, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1, verbose=1,shuffle=True)\n",
    "    train_mean=np.mean(train_scores,axis=1)\n",
    "    train_std=np.std(train_scores,axis=1)\n",
    "    test_mean=np.mean(test_scores,axis=1)\n",
    "    test_std=np.std(test_scores,axis=1)\n",
    "    plt.plot(train_sizes,train_mean,color='blue',marker='o',label='training accuracy')\n",
    "    plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "    plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',label='validation accuracy')\n",
    "    plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15,color='green')\n",
    "    plt.title(\"Learning Curve for Multinomial Naive Bayes\")\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53760975",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad35237",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnblearn(X_train1,y_train1,X_val1,y_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47419f",
   "metadata": {},
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae768653",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnblearn(X_train2,y_train2,X_val2,y_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a771d",
   "metadata": {},
   "source": [
    "DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_grid_learn(X_train,y_train,X_val,y_val):\n",
    "    dtree=DecisionTreeClassifier(random_state=0)\n",
    "    param_grid = {'criterion':[\"gini\",\"entropy\"],'max_depth': [10, 50, 100, None]}\n",
    "    grid_search = GridSearchCV(dtree, param_grid, cv=3,refit=True,n_jobs=-1,scoring='accuracy',verbose=1)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "    print(\"Accuracy: \",accuracy_score(y_val,grid_search.predict(X_val)))\n",
    "    print(classification_report(y_val,grid_search.predict(X_val)))\n",
    "    train_sizes, train_scores, test_scores = learning_curve(grid_search.best_estimator_, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1, verbose=1,shuffle=True)\n",
    "    train_mean=np.mean(train_scores,axis=1)\n",
    "    train_std=np.std(train_scores,axis=1)\n",
    "    test_mean=np.mean(test_scores,axis=1)\n",
    "    test_std=np.std(test_scores,axis=1)\n",
    "    plt.plot(train_sizes,train_mean,color='blue',marker='o',label='training accuracy')\n",
    "    plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "    plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',label='validation accuracy')\n",
    "    plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15,color='green')\n",
    "    plt.title(\"Learning Curve for Decision Tree\")\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd62ba0",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff306d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_grid_learn(X_train1,y_train1,X_val1,y_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de4f47",
   "metadata": {},
   "source": [
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_grid_learn(X_train2,y_train2,X_val2,y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e67754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2b2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af5913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b633f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1505b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
